{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7vf595kcHB3vjIRmUSWUy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"lEVJw9B4mma1","executionInfo":{"status":"error","timestamp":1763161574806,"user_tz":300,"elapsed":3368,"user":{"displayName":"Erin Mettler","userId":"09414721035378249418"}},"outputId":"2daa6056-9e06-4f95-c554-6dd307501271"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'detectron2'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2999683000.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Using detectron from Meta (uses Pytorch in the backend) for object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os\n","import sys\n","import json\n","import math\n","import glob\n","import yaml\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import random\n","import argparse\n","from typing import List, Dict, Optional\n","##Using detectron from Meta (uses Pytorch in the backend) for object detection\n","from detectron2.config import get_cfg\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultTrainer, DefaultPredictor\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","\n","#Utility functions\n","def set_seeds(seed: int = 42):\n","    import torch\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","\n","def ensure_dir(p: str):\n","    os.makedirs(p, exist_ok=True)\n","\n","#Register a COCO-format dataset to Detectron2 by name, with custom class names.\n","\n","def register_coco(name: str, json_path: str, img_root: str, classes: List[str]):\n","    if name in DatasetCatalog.list():\n","        MetadataCatalog.get(name).thing_classes = classes\n","        return\n","    register_coco_instances(name, {}, json_path, img_root)\n","    MetadataCatalog.get(name).thing_classes = classes\n","\n","\n","def build_cfg(\n","    classes: List[str],\n","    output_dir: str,\n","    ims_per_batch: int = 8,\n","    base_lr: float = 2.5e-4,\n","    max_iter: int = 50000,\n","    batch_size_per_image: int = 256,\n","    img_size_train: int = 1024,\n","    img_size_test: int = 1024,\n","    score_thresh_test: float = 0.25,\n",") -> \"CfgNode\":\n","    cfg = get_cfg()\n","    cfg.merge_from_file(model_zoo.get_config_file(\n","        \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n","    ))\n","    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n","        \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n","    )\n","    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n","    cfg.SOLVER.IMS_PER_BATCH = ims_per_batch\n","    cfg.SOLVER.BASE_LR = base_lr\n","    cfg.SOLVER.MAX_ITER = max_iter\n","    cfg.SOLVER.STEPS = []  # no LR decay by default\n","    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batch_size_per_image\n","    cfg.INPUT.MIN_SIZE_TRAIN = (img_size_train,)\n","    cfg.INPUT.MAX_SIZE_TRAIN = img_size_train\n","    cfg.INPUT.MIN_SIZE_TEST = img_size_test\n","    cfg.INPUT.MAX_SIZE_TEST = img_size_test\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh_test\n","    cfg.OUTPUT_DIR = output_dir\n","    ensure_dir(cfg.OUTPUT_DIR)\n","    return cfg\n","\n","\n","class Trainer(DefaultTrainer):\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        if output_folder is None:\n","            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n","        ensure_dir(output_folder)\n","        return COCOEvaluator(dataset_name, cfg, False, output_folder=output_folder)\n","\n","\n","#Convert Detectron2 predictor outputs to a list of {mask (H,W bool), class_id, score}.\n","def coco_instances_to_masks(outputs, score_thresh: float = 0.25):\n","    inst = outputs[\"instances\"].to(\"cpu\")\n","    keep = inst.scores >= score_thresh\n","    inst = inst[keep]\n","    results = []\n","    if inst.has(\"pred_masks\"):\n","        masks = inst.pred_masks.numpy()  # (N,H,W) bool\n","        classes = inst.pred_classes.numpy().tolist()\n","        scores = inst.scores.numpy().tolist()\n","        for m, c, s in zip(masks, classes, scores):\n","            results.append({\"mask\": m, \"class_id\": c, \"score\": float(s)})\n","    return results\n","\n","#Compute dominant roof azimuth (0°=North, 90°=East) from a binary mask via PCA on pixel coords.\n","def mask_to_azimuth_deg(mask_bool: np.ndarray) -> Optional[float]:\n","    ys, xs = np.nonzero(mask_bool)\n","    if xs.size < 10:\n","        return None\n","    pts = np.c_[xs, ys].astype(np.float32)\n","    pts -= pts.mean(axis=0, keepdims=True)\n","    # PCA via SVD\n","    _, _, vt = np.linalg.svd(pts, full_matrices=False)\n","    vx, vy = vt[0, 0], vt[0, 1]  # principal axis in image coords (x right, y down)\n","    angle_img = np.degrees(np.arctan2(vy, vx))   # 0 along +x\n","    azimuth = (90.0 - angle_img) % 180.0         # [0, 180)\n","    return float(azimuth)\n","\n","\n","def aggregate_tile_row(\n","    image_path: str,\n","    masks: List[Dict],\n","    class_names: List[str],\n","    aggregate_azimuth: str = \"median\"\n",") -> Dict:\n","    has_roofs = any(class_names[m[\"class_id\"]] == \"roof\" for m in masks)\n","    pv_present = any(class_names[m[\"class_id\"]] == \"pv\" for m in masks)\n","    num_roofs = sum(1 for m in masks if class_names[m[\"class_id\"]] == \"roof\")\n","\n","    roof_azis = []\n","    for m in masks:\n","        if class_names[m[\"class_id\"]] != \"roof\":\n","            continue\n","        az = mask_to_azimuth_deg(m[\"mask\"])\n","        if az is not None:\n","            roof_azis.append(az)\n","    if roof_azis:\n","        if aggregate_azimuth == \"median\":\n","            azimuth_tile = float(np.median(roof_azis))\n","        elif aggregate_azimuth == \"mean\":\n","            azimuth_tile = float(np.mean(roof_azis))\n","        else:\n","            azimuth_tile = float(np.median(roof_azis))\n","    else:\n","        azimuth_tile = \"\"\n","\n","    return {\n","        \"image path\": os.path.basename(image_path),\n","        \"has_roofs\": int(has_roofs),\n","        \"PV\": int(pv_present),\n","        \"num_roofs\": int(num_roofs),\n","        \"R/C\": \"\",\n","        \"Azimuth\": azimuth_tile\n","    }\n","\n","\n","def add_rc_from_counts(df: pd.DataFrame, count_col: str = \"num_roofs\") -> pd.DataFrame:\n","    \"\"\"\n","    Simple, tunable heuristic to fill R/C:\n","      - if no roofs: \"0\"\n","      - if many small roofs likely: \"R\"\n","      - else: \"C\"\n","    \"\"\"\n","    rc_vals = []\n","    for _, r in df.iterrows():\n","        try:\n","            n = int(r.get(count_col, 0))\n","        except Exception:\n","            n = 0\n","        if int(r.get(\"has_roofs\", 0)) == 0 or n == 0:\n","            rc_vals.append(\"0\")\n","        else:\n","            rc_vals.append(\"R\" if n >= 4 else \"C\")\n","    df[\"R/C\"] = rc_vals\n","    return df\n","\n","#subcommands\n","\n","# Training mask R-CNN on COCO-format datasets (train/val).\n","def cmd_train(args):\n","    set_seeds(args.seed)\n","\n","    classes = args.classes\n","    if len(classes) == 0:\n","        classes = [\"roof\"]\n","    #register datasets\n","    register_coco(args.train_name, args.train_json, args.train_root, classes)\n","    register_coco(args.val_name,   args.val_json,   args.val_root,   classes)\n","    cfg = build_cfg(\n","        classes=classes,\n","        output_dir=args.output_dir,\n","        ims_per_batch=args.ims_per_batch,\n","        base_lr=args.base_lr,\n","        max_iter=args.max_iter,\n","        batch_size_per_image=args.batch_size_per_image,\n","        img_size_train=args.img_size_train,\n","        img_size_test=args.img_size_test,\n","        score_thresh_test=args.score_thresh_test,\n","    )\n","    cfg.DATASETS.TRAIN = (args.train_name,)\n","    cfg.DATASETS.TEST = (args.val_name,)\n","    trainer = Trainer(cfg)\n","    trainer.resume_or_load(resume=False)\n","    trainer.train()\n","    evaluator = COCOEvaluator(cfg.DATASETS.TEST[0], cfg, False, output_dir=cfg.OUTPUT_DIR)\n","    val_loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\n","    metrics = inference_on_dataset(trainer.model, val_loader, evaluator)\n","    print(\"Validation metrics:\", metrics)\n","    print(\"Weights saved under:\", cfg.OUTPUT_DIR)\n","\n","#Run inference on a folder of PNG/JPEG tiles and write a CSV (optionally XLSX).\n","def cmd_infer(args):\n","    classes = args.classes\n","    if len(classes) == 0:\n","        classes = [\"roof\"]\n","    cfg = build_cfg(\n","        classes=classes,\n","        output_dir=os.path.join(os.path.dirname(args.weights), \"TMP_infer\"),\n","        img_size_test=args.img_size_test,\n","        score_thresh_test=args.score_thresh_test,\n","    )\n","    cfg.MODEL.WEIGHTS = args.weights\n","    predictor = DefaultPredictor(cfg)\n","    exts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\")\n","    imgs = []\n","    for e in exts:\n","        imgs.extend(glob.glob(os.path.join(args.img_dir, e)))\n","    imgs = sorted(imgs)\n","    if len(imgs) == 0:\n","        print(\"No images found in:\", args.img_dir, file=sys.stderr)\n","        sys.exit(1)\n","\n","    rows = []\n","    for p in tqdm(imgs, desc=\"Infer\"):\n","        im = cv2.imread(p, cv2.IMREAD_COLOR)\n","        if im is None:\n","            continue\n","        outputs = predictor(im)\n","        masks = coco_instances_to_masks(outputs, score_thresh=args.score_thresh_test)\n","        row = aggregate_tile_row(p, masks, classes, aggregate_azimuth=args.az_agg)\n","        rows.append(row)\n","\n","    df = pd.DataFrame(rows)\n","    if args.autofill_rc:\n","        df = add_rc_from_counts(df)\n","\n","    out_csv = args.out_csv\n","    ensure_dir(os.path.dirname(out_csv)) if os.path.dirname(out_csv) else None\n","    df.to_csv(out_csv, index=False)\n","    print(\"Wrote CSV:\", out_csv)\n","\n","    if args.out_xlsx:\n","        ensure_dir(os.path.dirname(args.out_xlsx)) if os.path.dirname(args.out_xlsx) else None\n","        with pd.ExcelWriter(args.out_xlsx) as w:\n","            df.to_excel(w, index=False, sheet_name=args.sheet_name)\n","        print(\"Wrote Excel:\", args.out_xlsx)\n","\n","\n","def cmd_export(args):\n","    \"\"\"\n","    Convert a CSV produced by `infer` to Excel and (optionally) add R/C heuristic.\n","    \"\"\"\n","    df = pd.read_csv(args.in_csv)\n","    if args.autofill_rc:\n","        df = add_rc_from_counts(df)\n","    ensure_dir(os.path.dirname(args.out_xlsx)) if os.path.dirname(args.out_xlsx) else None\n","    with pd.ExcelWriter(args.out_xlsx) as w:\n","        df.to_excel(w, index=False, sheet_name=args.sheet_name)\n","    print(\"Wrote Excel:\", args.out_xlsx)\n","\n","\n","def build_parser():\n","    p = argparse.ArgumentParser(\n","        description=\"DeepRoof-style roof/PV segmentation + azimuth (single-file).\"\n","    )\n","    sub = p.add_subparsers(dest=\"cmd\", required=True)\n","\n","    #Traininf\n","    t = sub.add_parser(\"train\", help=\"Train Mask R-CNN on COCO-format datasets.\")\n","    t.add_argument(\"--train-name\", default=\"roofs_train\", help=\"Detectron2 name for train dataset\")\n","    t.add_argument(\"--val-name\",   default=\"roofs_val\",   help=\"Detectron2 name for val dataset\")\n","    t.add_argument(\"--train-json\", required=True, help=\"COCO JSON for train\")\n","    t.add_argument(\"--train-root\", required=True, help=\"Image root for train\")\n","    t.add_argument(\"--val-json\",   required=True, help=\"COCO JSON for val\")\n","    t.add_argument(\"--val-root\",   required=True, help=\"Image root for val\")\n","    t.add_argument(\"--classes\",    nargs=\"*\", default=[\"roof\",\"pv\"], help=\"Class names in order\")\n","    t.add_argument(\"--output-dir\", default=\"runs/seg_maskrcnn\", help=\"where to save weights/metrics\")\n","    t.add_argument(\"--ims-per-batch\", type=int, default=8)\n","    t.add_argument(\"--base-lr\",    type=float, default=2.5e-4)\n","    t.add_argument(\"--max-iter\",   type=int, default=50000)\n","    t.add_argument(\"--batch-size-per-image\", type=int, default=256)\n","    t.add_argument(\"--img-size-train\", type=int, default=1024)\n","    t.add_argument(\"--img-size-test\",  type=int, default=1024)\n","    t.add_argument(\"--score-thresh-test\", type=float, default=0.25)\n","    t.add_argument(\"--seed\", type=int, default=42)\n","    t.set_defaults(func=cmd_train)\n","\n","    #Inference\n","    i = sub.add_parser(\"infer\", help=\"Infer on a folder of tiles and write CSV/XLSX with azimuth.\")\n","    i.add_argument(\"--weights\", required=True, help=\"Path to trained .pth/.pkl weights\")\n","    i.add_argument(\"--img-dir\", required=True, help=\"Folder of PNG/JPG/TIF tiles\")\n","    i.add_argument(\"--classes\", nargs=\"*\", default=[\"roof\",\"pv\"], help=\"Class names (order must match training)\")\n","    i.add_argument(\"--img-size-test\", type=int, default=1024)\n","    i.add_argument(\"--score-thresh-test\", type=float, default=0.25)\n","    i.add_argument(\"--az-agg\", choices=[\"median\",\"mean\"], default=\"median\", help=\"Aggregate roof azimuth per tile\")\n","    i.add_argument(\"--autofill-rc\", action=\"store_true\", help=\"Fill R/C via simple heuristic from counts\")\n","    i.add_argument(\"--out-csv\",  default=\"outputs/infer_table.csv\")\n","    i.add_argument(\"--out-xlsx\", default=\"\", help=\"Optional Excel path\")\n","    i.add_argument(\"--sheet-name\", default=\"L\")\n","    i.set_defaults(func=cmd_infer)\n","\n","    #Exporting results\n","    e = sub.add_parser(\"export\", help=\"Convert a CSV to Excel and optionally add R/C heuristic.\")\n","    e.add_argument(\"--in-csv\", required=True)\n","    e.add_argument(\"--out-xlsx\", required=True)\n","    e.add_argument(\"--sheet-name\", default=\"L\")\n","    e.add_argument(\"--autofill-rc\", action=\"store_true\")\n","    e.set_defaults(func=cmd_export)\n","    return p\n","\n","\n","def main():\n","    parser = build_parser()\n","    args = parser.parse_args()\n","    args.func(args)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}
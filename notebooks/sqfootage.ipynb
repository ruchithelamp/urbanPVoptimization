{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OBFvD7yXCvF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCECMln3dAnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob\n",
        "import re, os\n",
        "\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "LYyTx2uMdAxb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Aggregation\n",
        "We will open zips, clean up names, and stack all the training image and label data together."
      ],
      "metadata": {
        "id": "C77i-SjTXKfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_prefix(input_dir):\n",
        "  for fname in os.listdir(input_dir):\n",
        "    old_path = os.path.join(input_dir, fname)\n",
        "    if os.path.isfile(old_path) and \"-\" in fname:\n",
        "      new_name = fname.split(\"-\", 1)[1]   # take everything after first dash\n",
        "      new_path = os.path.join(input_dir, new_name)\n",
        "      os.rename(old_path, new_path)\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "def upload_to_colab(dest_path=\"/content\"):\n",
        "  uploaded = files.upload()  # opens the picker\n",
        "  for name, data in uploaded.items():\n",
        "      out_path = os.path.join(dest_path, name)\n",
        "      with open(out_path, \"wb\") as f:\n",
        "          f.write(data)\n",
        "      print(f\"Saved: {out_path}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "def unzip(zip, dest='/content/extracted_files' ):\n",
        "  with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dest)\n",
        "  print(f\"Successfully extracted '{zip}' to '{dest}'\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "def zip_and_download(inputs, zip_name=\"RoofAreaModel.zip\"):\n",
        "  \"\"\"\n",
        "  input: list of file paths\n",
        "  output: zip file\n",
        "  \"\"\"\n",
        "  zip_path = f\"/content/{zip_name}\"\n",
        "  with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    for path in inputs:\n",
        "      path = path.rstrip(\"/\")\n",
        "      if os.path.isdir(path):\n",
        "        # zip whole directory\n",
        "        for root, dirs, files_in_dir in os.walk(path):\n",
        "          for file in files_in_dir:\n",
        "            full_path = os.path.join(root, file)\n",
        "            rel_path = os.path.relpath(full_path, \"/content\")\n",
        "            z.write(full_path, rel_path)\n",
        "      elif os.path.isfile(path):\n",
        "        # zip single file\n",
        "        rel_path = os.path.relpath(path, \"/content\")\n",
        "        z.write(path, rel_path)\n",
        "      else:\n",
        "        print(f\"Skipping (not found): {path}\")\n",
        "\n",
        "  print(f\"Created zip: {zip_path}\")\n",
        "  files.download(zip_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "VDhq_Q4UXX8d"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploading the labelled data to /content in colab\n",
        "upload_to_colab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "lzdPGIbMBGTQ",
        "outputId": "67e1d658-c5f7-476a-89f6-de9f2dc3303a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd4e1c84-b84c-4adb-8cdd-a89b19e34108\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd4e1c84-b84c-4adb-8cdd-a89b19e34108\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # zipping individual lablled datasets\n",
        "# all_zips = glob.glob(\"/content/*.zip\")\n",
        "# for zip_file_path in all_zips:\n",
        "#   # Get the base name of the zip file (e.g., '30_chunk1_completed.zip')\n",
        "#   base_name = os.path.basename(zip_file_path)\n",
        "#   # Get the name without the .zip extension (e.g., '30_chunk1_completed')\n",
        "#   folder_name = os.path.splitext(base_name)[0]\n",
        "#   unzip(zip_file_path, dest=f'/content/extracted_files/{folder_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h-ZwWo8Dvkg",
        "outputId": "c031e83b-7b25-43f1-e4b4-12545ab029fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted '/content/30_chunk1_completed.zip' to '/content/extracted_files/30_chunk1_completed'\n",
            "Successfully extracted '/content/F_chunk1_completed.zip' to '/content/extracted_files/F_chunk1_completed'\n",
            "Successfully extracted '/content/E_chunk3_completed.zip' to '/content/extracted_files/E_chunk3_completed'\n",
            "Successfully extracted '/content/F_chunk3_completed.zip' to '/content/extracted_files/F_chunk3_completed'\n",
            "Successfully extracted '/content/N_chunk1_completed.zip' to '/content/extracted_files/N_chunk1_completed'\n",
            "Successfully extracted '/content/E_chunk1_completed.zip' to '/content/extracted_files/E_chunk1_completed'\n",
            "Successfully extracted '/content/E_chunk2_completed .zip' to '/content/extracted_files/E_chunk2_completed '\n",
            "Successfully extracted '/content/F_chunk2_completed.zip' to '/content/extracted_files/F_chunk2_completed'\n",
            "Successfully extracted '/content/E_chunk4_completed.zip' to '/content/extracted_files/E_chunk4_completed'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33d2fbee"
      },
      "source": [
        "def merge_labeled_sets(set_paths, output_root=\"mega_dataset\"):\n",
        "    \"\"\"\n",
        "    Merge multiple labeled datasets into a single 'mega_dataset'.\n",
        "    - Prevents name collisions by prefixing files with a simplified set identifier.\n",
        "    \"\"\"\n",
        "\n",
        "    images_out = os.path.join(output_root, \"images\")\n",
        "    labels_out = os.path.join(output_root, \"labels\")\n",
        "\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(images_out, exist_ok=True)\n",
        "    os.makedirs(labels_out, exist_ok=True)\n",
        "\n",
        "    for set_path in set_paths:\n",
        "        # Extract the full name of the dataset chunk folder (e.g., 'E_chunk1_completed')\n",
        "        full_set_name = os.path.basename(set_path.rstrip(\"/\"))\n",
        "        # Extract city prefix (e.g., 'E' or '30') from full dataset name\n",
        "        # This assumes the prefix is the 1st part before the first _\n",
        "        city_prefix = full_set_name.split('_')[0]\n",
        "        print(f\"Merging {full_set_name} with prefix '{city_prefix}': \")\n",
        "\n",
        "        imgs_in = os.path.join(set_path, \"images\")\n",
        "        lbls_in = os.path.join(set_path, \"labels\")\n",
        "\n",
        "        # Process images\n",
        "        for img_file in glob.glob(os.path.join(imgs_in, \"*\")):\n",
        "            base = os.path.basename(img_file) # name of image and its label\n",
        "            # New image name will be '<city_prefix>_original_name.ext'\n",
        "            new_img = f\"{city_prefix}_{base}\"\n",
        "\n",
        "            shutil.copy(img_file, os.path.join(images_out, new_img))\n",
        "\n",
        "            # Find and copy the matching label file from OG labels folder\n",
        "            label_name = os.path.splitext(base)[0] + \".txt\"\n",
        "            label_path = os.path.join(lbls_in, label_name)\n",
        "            if os.path.exists(label_path):\n",
        "                # New label name will be '<city_prefix>_original_name.txt'\n",
        "                new_lbl = f\"{city_prefix}_{label_name}\"\n",
        "                # move respective labels txt to MErged folder's labels\n",
        "                shutil.copy(label_path, os.path.join(labels_out, new_lbl))\n",
        "\n",
        "    print(\"Merged dataset created successfully!\")\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "def list_dataset_folders(root=\"/content/dataset_sets\"):\n",
        "    \"\"\"\n",
        "    Return a list of all labeled dataset folders inside root.\n",
        "    Folders must each contain 'images' and 'labels' subdirectories.\n",
        "    \"\"\"\n",
        "    folders = []\n",
        "    for entry in os.listdir(root):\n",
        "        path = os.path.join(root, entry)\n",
        "        # Check if it's a directory and contains both 'images' and 'labels' folders\n",
        "        if os.path.isdir(path) and \\\n",
        "           os.path.isdir(os.path.join(path, \"images\")) and \\\n",
        "           os.path.isdir(os.path.join(path, \"labels\")):\n",
        "            folders.append(path)\n",
        "    return folders"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets join the individual labelled datasets into one MEGASET\n",
        "# i hope the names dont collide\n",
        "\n",
        "# list of all individual labelled dataset folder names\n",
        "set_paths = list_dataset_folders(root=\"/content/extracted_files\")\n",
        "\n",
        "# merge folders in set_path\n",
        "merge_labeled_sets(set_paths)\n",
        "# print(set_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv9tlghIPs-6",
        "outputId": "c5503a08-b7b3-415c-f1ae-5067fa21194c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging E_chunk5_completed with prefix 'E': \n",
            "Merging F_chunk3_completed with prefix 'F': \n",
            "Merging N_chunk1_completed with prefix 'N': \n",
            "Merging 30_chunk1_completed with prefix '30': \n",
            "Merging E_chunk4_completed with prefix 'E': \n",
            "Merging F_chunk2_completed with prefix 'F': \n",
            "Merging E_chunk3_completed with prefix 'E': \n",
            "Merging F_chunk1_completed with prefix 'F': \n",
            "Merging E_chunk2_completed with prefix 'E': \n",
            "Merged dataset created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_val(\n",
        "    input_root=\"mega_dataset\",\n",
        "    output_root=\"yolo_dataset\",\n",
        "    val_size=0.1,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"Create YOLO train/val folders for segmentation.\"\"\"\n",
        "\n",
        "    img_in = os.path.join(input_root, \"images\")\n",
        "    lbl_in = os.path.join(input_root, \"labels\")\n",
        "\n",
        "    images = sorted(glob.glob(os.path.join(img_in, \"*\")))\n",
        "    train_imgs, val_imgs = train_test_split(\n",
        "        images, test_size=val_size, random_state=seed\n",
        "    )\n",
        "\n",
        "    # create folder tree\n",
        "    for p in [\n",
        "        \"images/train\",\"images/val\",\n",
        "        \"labels/train\",\"labels/val\"\n",
        "    ]:\n",
        "        os.makedirs(os.path.join(output_root, p), exist_ok=True)\n",
        "\n",
        "    def copy_pairs(img_list, split):\n",
        "        for img_path in img_list:\n",
        "            base = os.path.basename(img_path)\n",
        "            stem = os.path.splitext(base)[0]\n",
        "            lbl_path = os.path.join(lbl_in, stem + \".txt\")\n",
        "\n",
        "            shutil.copy(img_path, os.path.join(output_root, f\"images/{split}\", base))\n",
        "            if os.path.exists(lbl_path):\n",
        "                shutil.copy(lbl_path, os.path.join(output_root, f\"labels/{split}\", stem + \".txt\"))\n",
        "\n",
        "    copy_pairs(train_imgs, \"train\")\n",
        "    copy_pairs(val_imgs, \"val\")\n",
        "\n",
        "    print(f\"Train Test split is in '{output_root}'.\")"
      ],
      "metadata": {
        "id": "1d5Uur2nXYnN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset for train and split\n",
        "# it should be like\n",
        "# yolo_dataset\n",
        "# > images > train/, val/\n",
        "# > labels > train/, val/\n",
        "\n",
        "split_train_val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E66owlLKiDJF",
        "outputId": "37d9147f-73a6-4dd5-978c-cc3ab3186ab9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Test split is in 'yolo_dataset'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_yolo_yaml(output_root=\"yolo_dataset\", yaml_name=\"data.yaml\"):\n",
        "    \"\"\"Create YOLO segmentation config file.\"\"\"\n",
        "\n",
        "    yaml_path = os.path.join(output_root, yaml_name)\n",
        "    content = f\"\"\"\n",
        "path: {output_root}\n",
        "\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "names:\n",
        "  0: PV\n",
        "  1: roof\n",
        "\"\"\".strip()\n",
        "\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f\"YAML is in {yaml_path}\")"
      ],
      "metadata": {
        "id": "gZlBFudNzjsS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_yolo_yaml()"
      ],
      "metadata": {
        "id": "rv8SUgmEzjmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a1d353-73aa-41c5-b658-d6d71bcd1d5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML is in yolo_dataset/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# does yolo comman work\n",
        "# yolo\n",
        "# !pip install ultralytics\n",
        "# !yolo"
      ],
      "metadata": {
        "id": "xy1M_I3hsr2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=train \\\n",
        "     model=yolov8s-seg.pt \\\n",
        "     data=/content/yolo_dataset/data.yaml \\\n",
        "     epochs=40 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBI0bpXNsryj",
        "outputId": "0a967bef-7609-4853-d0be-c20ed3815d60"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-seg.pt to 'yolov8s-seg.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 22.8MB 42.4MB/s 0.5s\n",
            "Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 174.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2771318  ultralytics.nn.modules.head.Segment          [2, 32, 128, [128, 256, 512]] \n",
            "YOLOv8s-seg summary: 151 layers, 11,790,870 parameters, 11,790,854 gradients, 40.2 GFLOPs\n",
            "\n",
            "Transferred 411/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 428.2MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2580.6Â±1066.7 MB/s, size: 105.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train... 750 images, 268 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 931/931 1.4Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_dataset/images/train/E_73b4cd47-053.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_dataset/images/train/E_80fbeca1-215.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 899.3Â±524.7 MB/s, size: 119.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val... 85 images, 27 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 1.1Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/labels/val.cache\n",
            "Plotting labels to /content/runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/40      4.52G      1.288      2.479      2.384      1.334         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 3.3it/s 17.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.0it/s 1.3s\n",
            "                   all        104        332      0.248      0.361      0.257      0.145      0.246      0.454      0.242      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/40      5.69G      1.213      1.915       1.61      1.288         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        104        332      0.707      0.249      0.186      0.103      0.704      0.239      0.171     0.0829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/40      5.73G      1.298      1.997      1.566      1.327         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.102      0.286      0.107     0.0586     0.0934      0.267     0.0926     0.0413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/40      5.77G      1.228      1.947      1.515      1.295         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.192      0.351       0.21      0.108      0.226      0.406      0.235     0.0979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/40      5.81G      1.215      1.871      1.469      1.294         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        104        332      0.737      0.325      0.236      0.127      0.737      0.311      0.233      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/40      5.85G       1.16      1.844      1.414      1.267         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        104        332      0.483      0.396      0.374      0.216      0.478      0.391      0.373      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/40      5.89G      1.175      1.822      1.367      1.265         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.774      0.334       0.32      0.189      0.766      0.346      0.329      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/40      5.93G      1.141      1.752      1.315      1.244         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332       0.43      0.543      0.495      0.269      0.433      0.547      0.511      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/40      5.97G       1.15      1.816      1.335      1.255         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.515      0.416      0.385      0.224      0.508      0.407      0.377        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/40      6.01G      1.079      1.678      1.305      1.216         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.514      0.463      0.451      0.273       0.37      0.559      0.472      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/40      6.05G      1.074      1.666      1.265       1.22         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        104        332      0.556       0.53        0.5      0.268      0.563      0.529       0.51      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/40      6.09G      1.048      1.651      1.232      1.189         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.482      0.565      0.517       0.29      0.482      0.565       0.53      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/40      6.13G      1.065      1.651       1.27      1.216         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        104        332      0.681      0.423      0.489      0.304      0.557      0.532      0.519      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/40      6.17G      1.022      1.603      1.197      1.179         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.583      0.495      0.443      0.238      0.581      0.493      0.443      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/40      6.21G     0.9908      1.531      1.146      1.163         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332       0.45      0.568      0.532      0.343        0.7      0.639       0.63      0.337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/40      6.25G     0.9886      1.547      1.118      1.151         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.581      0.611      0.589      0.358       0.58      0.611      0.602      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/40      6.29G      1.006      1.513      1.138      1.161         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.482      0.576      0.572      0.387      0.467      0.594      0.572      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/40      6.33G     0.9571      1.469      1.091      1.137         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332       0.52      0.646      0.606      0.346      0.647      0.707      0.663      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/40      6.37G     0.9471      1.479      1.071      1.139         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.729      0.657      0.723      0.492      0.731      0.662      0.725       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/40      6.41G     0.9734      1.533      1.105      1.149         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.574      0.757      0.637      0.396      0.575      0.758      0.635      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/40      6.46G     0.9526       1.46      1.099      1.143          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.676      0.709      0.711      0.485      0.677       0.71      0.711      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/40      6.49G     0.9452      1.499      1.053      1.138          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.672      0.548      0.596      0.388      0.674      0.552      0.597      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/40      6.53G     0.9163       1.43       1.02      1.122          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.665      0.777      0.757      0.517      0.663      0.776      0.757      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/40      6.57G     0.9165      1.424      1.041       1.12         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.588      0.818      0.663      0.432      0.588      0.818      0.672      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/40      6.61G     0.9016      1.397      1.005      1.115         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.5it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.766      0.734      0.777      0.545      0.769      0.737      0.779      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/40      6.65G     0.9067      1.419     0.9825      1.109          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.689      0.738      0.689      0.462      0.694      0.744      0.704      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/40      6.69G     0.8713      1.362     0.9619      1.087         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.786      0.812      0.792      0.522      0.788      0.815      0.793      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/40      6.73G     0.8914      1.353      1.019      1.101          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.595      0.766       0.72      0.471      0.692      0.765      0.733      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/40      6.77G     0.8678      1.343     0.9691      1.086          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.676       0.75      0.733      0.493      0.679      0.754      0.744      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/40      6.81G      0.869      1.331     0.9287      1.082         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.787      0.808      0.802      0.533      0.789      0.808      0.801      0.515\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/40      6.85G     0.8419      1.324     0.9695      1.098          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.3it/s 13.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.647      0.744      0.689      0.435      0.646      0.754        0.7      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/40      6.89G     0.8386      1.326     0.9245      1.107          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.791      0.647      0.786      0.517      0.793      0.648      0.785      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/40      6.93G     0.8238       1.28     0.9105      1.091         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.783      0.697      0.717      0.473      0.771      0.712      0.759      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/40      6.97G     0.8004      1.242     0.8724      1.079          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        104        332      0.748      0.775      0.759      0.509      0.752       0.78      0.762      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/40      7.01G     0.7968      1.251     0.8799      1.071          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 1.0s\n",
            "                   all        104        332      0.783      0.805       0.78      0.516      0.789      0.806      0.783      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/40      7.05G     0.7767      1.243     0.9274      1.048          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.674       0.73      0.746      0.521      0.675      0.732      0.746      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/40      7.09G     0.7596      1.187     0.8274      1.054          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.691      0.796      0.762      0.494      0.694      0.801      0.764      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/40      7.13G      0.746      1.189     0.7878      1.052         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332      0.666      0.794       0.75      0.487      0.669      0.799      0.752       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/40      7.17G     0.7586      1.186     0.7922      1.045          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        104        332       0.68      0.741      0.765      0.485      0.682      0.744      0.779      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/40      7.21G     0.7251      1.165     0.7831      1.034          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 59/59 4.6it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 1.0s\n",
            "                   all        104        332      0.741      0.723       0.77      0.495      0.743      0.726      0.779      0.481\n",
            "\n",
            "40 epochs completed in 0.164 hours.\n",
            "Optimizer stripped from /content/runs/segment/train/weights/last.pt, 23.9MB\n",
            "Optimizer stripped from /content/runs/segment/train/weights/best.pt, 23.9MB\n",
            "\n",
            "Validating /content/runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8s-seg summary (fused): 85 layers, 11,780,374 parameters, 0 gradients, 39.9 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.7it/s 1.5s\n",
            "                   all        104        332      0.789      0.839      0.807      0.535      0.788      0.838      0.805      0.517\n",
            "                    PV          5         10          1      0.847      0.909      0.572          1      0.847      0.909      0.562\n",
            "                  roof         77        322      0.578      0.832      0.704      0.498      0.575      0.829      0.701      0.472\n",
            "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0L4C1zrCsrvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzRBOLnVsrsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Area Calculations"
      ],
      "metadata": {
        "id": "G3ujNwVfwuTE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb2OjB-msrpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6V1foxgsrmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxoJMpcGsrc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86b128f2",
        "outputId": "381b103d-c878-4dbc-c34d-8095cf586268"
      },
      "source": [
        "\n",
        "\n",
        "# extracted_root = '/content/extracted_files'\n",
        "\n",
        "# for fol in os.listdir(extracted_root):\n",
        "#     dataset = os.path.join(extracted_root, fol)\n",
        "\n",
        "#     if os.path.isdir(dataset):\n",
        "#         print(f\"Processing folder: {fol}\")\n",
        "#         for item_name in os.listdir(dataset):\n",
        "#             item_path = os.path.join(dataset, item_name)\n",
        "\n",
        "#             if os.path.isdir(item_path):\n",
        "#                 if \"images\" in item_name.lower() and item_name != \"images\":\n",
        "#                     new_path = os.path.join(dataset, \"images\")\n",
        "#                     os.rename(item_path, new_path)\n",
        "\n",
        "#                 elif \"labels\" in item_name.lower() and item_name != \"labels\":\n",
        "#                     new_path = os.path.join(dataset, \"labels\")\n",
        "#                     os.rename(item_path, new_path)\n",
        "\n",
        "#                 else:\n",
        "#                     print(f\"  Skipping '{item_name}' \")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: E_chunk5_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: F_chunk3_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: N_chunk1_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: .ipynb_checkpoints\n",
            "Processing folder: 30_chunk1_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: E_chunk4_completed\n",
            "Processing folder: F_chunk2_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: E_chunk3_completed\n",
            "Processing folder: F_chunk1_completed\n",
            "  Skipping 'images' \n",
            "  Skipping 'labels' \n",
            "Processing folder: E_chunk2_completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# count files\n",
        "\n",
        "!ls -l mega_dataset/images | grep -v ^d | wc -l\n",
        "!ls -l mega_dataset/labels | grep -v ^d | wc -l"
      ],
      "metadata": {
        "id": "IBrcPIjJzjjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d14b9e-3e3a-428c-932c-7e8f76f2ca16"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1036\n",
            "836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff91492f",
        "outputId": "817a4e8c-2455-4a2f-9b14-5d2058a75620"
      },
      "source": [
        "# listing first five files\n",
        "\n",
        "!ls mega_dataset/images | tail -n 5\n",
        "!ls mega_dataset/labels | tail -n 5"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_eea6b429-tile_87.png\n",
            "N_f11afc34-tile_21.png\n",
            "N_f69a1851-tile_49.png\n",
            "N_fa258cd3-tile_78.png\n",
            "N_fc2a847b-tile_15.png\n",
            "N_eea6b429-tile_87.txt\n",
            "N_f11afc34-tile_21.txt\n",
            "N_f69a1851-tile_49.txt\n",
            "N_fa258cd3-tile_78.txt\n",
            "N_fc2a847b-tile_15.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_and_download([\"/content/mega_dataset\"])\n",
        "zip_and_download([\"/content/yolo_dataset\", \"/content/runs\", \"/content/models\"])"
      ],
      "metadata": {
        "id": "rMKHqNcdzjcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d583d7df-f395-4362-9afa-d45d92d3869f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created zip: /content/RoofAreaModel.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf4fb1f7-1a45-4166-9e69-d83c8d5cbfda\", \"RoofAreaModel.zip\", 222995256)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lYWU8jJXYy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/models"
      ],
      "metadata": {
        "id": "yjAoJQE5XZrJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJBE5ucU46fr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}